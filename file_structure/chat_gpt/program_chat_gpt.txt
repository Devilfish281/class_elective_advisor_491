Developer: Developer: # Project Title
- class elective advisor Project class 491

# Role and Objective
- Serve as a Python developer working on the 'Smart Elective Advisor: AI-Driven Course Selection Tool for CS Students' using modern Python tooling and best practices.
- **Programming language:** Python (already installed).
- **Manages virtual environments:** Poetry (already installed).
- **Package installer for Python:** Poetry.
- **Operating System:** Windows 11.
- **Framework:** LangChain, LangGraph.

# Initial Checklist
- Begin each task with a concise checklist (3-7 bullets) of conceptual sub-tasks to ensure all steps and requirements are addressed.

# Instructions
- Use Visual Studio Code on Windows 11 to develop in Python.
- Manage packages and virtual environments with Poetry.
- Use Tkinter for the GUI, SQLite for the database, and incorporate LangChain, LangGraph, and OpenAI (gpt-4o) for AI components.
- Employ Git and GitHub for version control.
- Use Sphinx for documentation generation.
- **Check my code for errors and suggest improvements.**

## Coding and Commenting Guidelines
- When adding new lines of code, annotate with `# Added Code` at the end of the line.
- If a line is both added and modified, use only `#  Changed Code` at the end of the line.
- Do **not** comment on command-line instructions.
- Provide complete code context when submitting changes.
- When editing code:
  1. Clearly state any relevant assumptions.
  2. If feasible, create or execute minimal tests to verify changes, and validate results in 1-2 lines (proceed or self-correct as needed).
  3. Provide review-ready diffs.
  4. Follow the established project style conventions.
- **Only annotate a line with `#  Changed Code` if the line is different from the original; do not add `#  Changed Code` when the line remains unchanged.**

# Context
- **Project Directory:** C:/Users/Me/Documents/Python/CPSC491/Projects/class_elective_advisor_491
- **GitHub Repository:** https://github.com/Devilfish281/class_elective_advisor.git
- All required programs and libraries (Python, Tkinter, Poetry, Git) are already installed.

# Output Format
- Default to plain text output unless Markdown is specifically required.
- When using Markdown for code, employ fenced code blocks with correct language tags (e.g., ```python).
- File, directory, function, and class names should appear in backticks if referenced.
- Escape math notation if present.

# Verbosity
- Use concise summaries for general output.
- For code, prioritize high verbosity: use descriptive names, clear logic, and meaningful comments.

# Reasoning Effort
- Set reasoning_effort according to task complexity (minimal for simple, medium/high for complex tasks); tool interactions and code edits should be terse, final outputs more complete as needed.

# Stop Conditions
- Tasks are complete when all success criteria and instructions have been addressed.
- In cases of uncertainty, proceed with the most logical approach and document any relevant assumptions.
- Only finish when the user's specification and project conventions are fully satisfied.

********************************
Check my code for errors and improvements.



The File structure for my program is BELOW:
├── C:\Users\Me\Documents\Python\CPSC491\Projects\class_elective_advisor_491/
│   ├── .coverage
│   ├── .env
│   ├── .env.example
│   ├── .gitignore
│   ├── README.md
│   ├── app.log
│   ├── launch_old.json
│   ├── main.py
│   ├── poetry.lock
│   ├── pyproject.toml
│   ├── pytest.ini
│   └── run_debug.py
    ├── .github/
    │   └── pull_request_template.md
        └── workflows/
            └── pytest.yml
    ├── .pytest_cache/
    │   ├── .gitignore
    │   ├── CACHEDIR.TAG
    │   └── README.md
        └── v/
            └── cache/
                ├── lastfailed
                └── nodeids
    ├── .vscode/
    │   └── launch.json.bak
    ├── ai_integration/
    │   ├── ai_dev_notes.md
    │   └── ai_module.py
    ├── artifacts/
    │   └── report.html
    ├── database/
    │   └── db_setup.py
    ├── debugpy.log/
    │   ├── debugpy.adapter-28864.log
    │   ├── debugpy.adapter-33968.log
    │   ├── debugpy.pydevd.35744.log
    │   ├── debugpy.pydevd.37552.log
    │   ├── debugpy.server-35744.log
    │   └── debugpy.server-37552.log
    ├── src/
        └── class_elective_advisor_491/
            └── __init__.py
    ├── tests/
    │   ├── __init__.py
    │   ├── conftest.py
    │   ├── test_ai_module.py
    │   └── test_load_env.py
        └── logs/
            └── test_ai.md
    ├── ui/
    │   └── gui.py
    └── utilities/
        ├── __init__.py
        ├── load_env.py
        └── logger_setup.py

########################################
Here is my code for main.py BELOW:
########################################

```python
# main.py
"""Smart Elective Advisor - CLI entrypoint and test runners.

This module provides CLI entrypoints to run individual subsystem tests (AI, DB, UI)
or to start the full application. The functions in this module are documented with
Sphinx/reStructuredText field lists so Sphinx autodoc (and napoleon) will render
the function signatures and parameter/return documentation cleanly.

Usage examples (from project root):
    poetry run python main.py -ai 1
    poetry run python main.py -db 2
    poetry run python main.py -ui 3
    poetry run python main.py -ai 1 -db 3 -ui 2

Notes:
- For Sphinx, enable `sphinx.ext.autodoc` and optionally `sphinx.ext.napoleon` to
  accept Google / NumPy-style docstrings. The docstrings here use classic reST
  field lists so they work with autodoc out of the box.
"""
import argparse
import logging
import sys
from typing import Optional

from utilities.logger_setup import setup_logger


_EXIT_DESCRIPTIONS = {
    "setup": {
        0: "Environment loaded: OK.",
        2: "Environment load failed (e.g., OPENAI_API_KEY missing/invalid).",
    },
    "ai_test": {
        0: "AI test passed.",
        1: "AI test failed.",
        2: "AI test raised an exception.",
    },
    "db_test": {
        0: "DB test passed.",
        1: "DB test failed.",
        2: "DB test raised an exception.",
    },
    "ui_test": {
        0: "UI test passed.",
        1: "UI test failed or raised an exception.",
    },
    "main": {
        0: "Program finished successfully.",
        3: "Database initialization failed.",
        4: "AI initialization failed.",
        5: "UI initialization failed.",
        130: "Interrupted by user (KeyboardInterrupt/SIGINT).",
    },
    "tests": {
        0: "All requested tests passed.",
        1: "At least one test failed.",
        2: "At least one test raised an exception.",
    },
}


def describe_exit_code(context: str, code: int) -> str:
    """Return a human-readable description for a given exit code in a context."""
    return _EXIT_DESCRIPTIONS.get(context, {}).get(code, f"Unknown exit code {code}.")


def report_exit_code(context: str, code: int) -> None:
    """Log and print a description of the exit code for the given context."""
    msg = describe_exit_code(context, code)
    logging.getLogger(__name__).info("[%s] %s (code=%s)", context, msg, code)
    print(f"[{context}] {msg} (code={code})")


def _run_ai_test(option: int) -> int:
    """Run an AI subsystem test and return a process-style exit code.

    This wrapper imports and calls :func:`ai_integration.ai_module.main_test_ai`
    passing the received option integer through.

    :param option: integer selecting the AI test variant (1..3)
    :type option: int
    :returns: 0 on success, 1 on test-level failure, 2 on unexpected exception
    :rtype: int
    :raises ImportError: if the AI test module cannot be imported
    """
    logger = logging.getLogger(__name__)
    try:
        from ai_integration.ai_module import main_test_ai

        logger.info("Running AI test...")
        ok = main_test_ai(option)
        if ok:
            logger.info("AI test passed.")
            return 0
        logger.error("AI test failed.")
        return 1
    except Exception:
        logger.exception("Exception while running AI test")
        return 2


def _run_db_test(option: int) -> int:
    """Run a DB subsystem test and return a process-style exit code.

    This wrapper imports and calls :func:`database.db_setup.main_test_db`
    passing the received option integer through.

    :param option: integer selecting the DB test variant (1..3)
    :type option: int
    :returns: 0 on success, 1 on test-level failure, 2 on unexpected exception
    :rtype: int
    :raises ImportError: if the database module cannot be imported
    """
    logger = logging.getLogger(__name__)
    try:
        from database.db_setup import main_test_db

        logger.info("Running DB test...")
        ok = main_test_db(option)
        if ok:
            logger.info("DB test passed.")
            return 0
        logger.error("DB test failed.")
        return 1
    except Exception:
        logger.exception("Exception while running DB test")
        return 2


def _run_ui_test(option: int) -> int:
    """Run a UI subsystem test and return a process-style exit code.

    This wrapper imports and calls :func:`ui.gui.main_test_ui` which provides
    several UI test variants (for example: launch-and-block, create/destroy,
    auto-close for CI). Use the integer `option` to pick the variant.

    :param option: integer selecting the UI test variant (1..3)
    :type option: int
    :returns: 0 on success, 1 on failure or exception
    :rtype: int
    :raises ImportError: if the UI module cannot be imported
    """
    logger = logging.getLogger(__name__)
    try:
        from ui.gui import main_int_ui

        logger.info("Launching UI (test mode)...")
        ok = main_int_ui(option)
        if ok:
            logger.info("UI test passed.")
            return 0
        logger.error("UI test failed.")
        return 1

    except Exception:
        logger.exception("Exception while running UI")
        return 1


def main_setup() -> int:
    """Set up logging and environment for the application.

    This function configures the project logger by calling :func:`setup_logger`
    and then attempts to load and validate environment variables using
    :func:`utilities.load_env.load_environment`.

    :returns: 0 on success, 2 if environment loading failed
    :rtype: int
    :raises ValueError: when environment variables are missing or invalid
    """

    setup_logger()

    import logging

    logger = logging.getLogger(__name__)

    from utilities.load_env import load_environment

    try:
        load_environment()
    except ValueError as e:
        logger.error("Error loading environment: %s", e)
        return 2

    return 0


def main() -> int:
    """Run the full application (database init → AI init → UI).

    The function performs the high-level startup sequence:
    1. Initialize database via :func:`database.db_setup.main_int_db`
    2. Initialize AI via :func:`ai_integration.ai_module.main_int_ai`
    3. Start the UI via :func:`ui.gui.main_int_ui` (blocking call)

    Exit codes:
      * 0 — success (program finished)
      * 3 — database initialization failed
      * 4 — AI initialization failed
      * 5 — UI initialization failed

    :returns: exit code suitable for `sys.exit()`
    :rtype: int
    :raises Exception: any unexpected exception will be logged and results in non-zero exit
    """
    logger = logging.getLogger(__name__)

    from database.db_setup import main_int_db

    try:
        main_int_db()
    except Exception as e:
        logger.exception("Database initialization failed: %s", e)
        return 3

    from ai_integration.ai_module import main_int_ai

    try:
        main_int_ai()
    except Exception as e:
        logger.exception("AI initialization failed: %s", e)
        return 4

    from ui.gui import main_int_ui

    try:
        main_int_ui()
    except Exception as e:
        logger.exception("UI initialization failed: %s", e)
        return 5

    logger.info("Program finished successfully.")
    import logging

    logging.shutdown()
    return 0


if __name__ == "__main__":
    exit_code = 0

    exit_code: int = main_setup()
    report_exit_code("setup", exit_code)
    if exit_code != 0:
        sys.exit(exit_code)

    """
    DEBUGGING / TESTING USAGE:
    poetry run python run_debug.py -ai 1

    poetry run python main.py -ai 1
    poetry run python main.py -db 2
    poetry run python main.py -ui 3

    poetry run python main.py -ai 1 -db 3 -ui 2

    """

    parser = argparse.ArgumentParser(description="Smart Elective Advisor CLI")
    parser.add_argument(
        "-db",
        type=int,
        choices=[1, 2, 3],
        help="Run DB test variant (1..3) and pass the number to _run_db_test()",
    )
    parser.add_argument(
        "-ai",
        type=int,
        choices=[1, 2, 3],
        help="Run AI test variant (1..3) and pass the number to _run_ai_test()",
    )
    parser.add_argument(
        "-ui",
        type=int,
        choices=[1, 2, 3],
        help="Run UI test variant (1..3) and pass the number to _run_ui_test()",
    )
    args = parser.parse_args()

    if args.ai or args.db or args.ui:
        exit_code = 0
        if args.ai:
            rc = _run_ai_test(args.ai)
            report_exit_code("ai_test", rc)
            exit_code = exit_code or rc
        if args.db:
            rc = _run_db_test(args.db)
            report_exit_code("db_test", rc)
            exit_code = exit_code or rc
        if args.ui:
            rc = _run_ui_test(args.ui)
            report_exit_code("ui_test", rc)
            exit_code = exit_code or rc

        summary_ctx = "tests"
        report_exit_code(summary_ctx, 0 if exit_code == 0 else exit_code)
        sys.exit(exit_code)

    try:
        exit_code: int = main()
    except KeyboardInterrupt:
        logging.getLogger(__name__).info("Interrupted by user (KeyboardInterrupt).")
        exit_code = 130

    report_exit_code("main", exit_code)
    sys.exit(exit_code)```

########################################
Here is my code for run_debug.py BELOW:
########################################

```python
# run_debug.py
import runpy
import sys
import traceback

import debugpy

try:
    print(
        "debugpy: attempting to listen on 5678 — attach your debugger now", flush=True
    )
    debugpy.log_to("debugpy.log")
    debugpy.listen(5678)
    print("debugpy: listen() returned, now waiting for client...", flush=True)
    debugpy.wait_for_client()
    attached = debugpy.is_client_connected()
    print("debugpy client attached?", attached)
    print("debugpy: client attached — continuing to run main.py", flush=True)

    sys.argv = ["main.py"] + sys.argv[1:]
    runpy.run_path("main.py", run_name="__main__")
except Exception:
    print("Exception in run_debug.py:", flush=True)
    traceback.print_exc()
    try:
        import time

        time.sleep(3)
    except Exception:
        pass
    raise```

########################################
Here is my code for ai_module.py BELOW:
########################################

```python
import importlib.util
import json
import logging
import os
import re
import sys
from typing import Optional

logger = logging.getLogger(__name__)


def main_int_ai() -> bool:
    """
    Initialize AI integration.
    - In production, this would set up OpenAI/LLM clients, keys, rate-limiters, etc.
    - For now, we log initialization and verify OPENAI_API_KEY presence.
    """
    logger.info("Initializing AI Module...")
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.warning("OPENAI_API_KEY not set; AI features disabled.")
        return False
    logger.info("AI configuration found (client initialization placeholder).")


    return True


def main_test_ai(option: int) -> bool:
    """
    Lightweight test for AI integration used by CLI -ai.
    Returns True if basic check passes (API key present), False otherwise.
    """
    logger.info("Running AI module test...")

    api_key = os.getenv("OPENAI_API_KEY")

    if option == 1:
        ret_value = main_int_ai()
        return ret_value

    elif option == 2:
        if not api_key:
            logger.warning("main_test_ai option 2: OPENAI_API_KEY not set.")
            return False
        masked = api_key[:8] + ("*" * max(0, len(api_key) - 8))
        logger.info("main_test_ai option 2: API key masked prefix: %s", masked)
        return True

    elif option == 3:
        spec = importlib.util.find_spec("openai")
        if spec is None:
            logger.warning("main_test_ai option 3: 'openai' package not found.")
            return False
        logger.info("main_test_ai option 3: 'openai' package is installed.")
        return True

    else:
        logger.error("main_test_ai: unknown option %s", option)
        return False```

########################################
Here is my code for db_setup.py BELOW:
########################################

```python
import logging
import os
import sqlite3
import tempfile
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)


def create_connection(db_file) -> Optional["sqlite3.Connection"]:
    """Create a database connection to the SQLite database specified by db_file."""
    conn = None
    try:
        conn = sqlite3.connect(db_file)
        logger.info("Connected to SQLite database: %s", db_file)
        return conn
    except sqlite3.Error as e:
        logger.error("SQLite connection error: %s", e)
    return conn


def create_tables(conn):
    """Create tables in the SQLite database."""
    try:
        cursor = conn.cursor()
        cursor.execute("PRAGMA foreign_keys = ON;")

        cursor.execute(
            """CREATE TABLE IF NOT EXISTS metadata (
            k TEXT PRIMARY KEY,
              v TEXT);
              """
        )

        conn.commit()
        logger.info("All tables created successfully.")

    except sqlite3.Error as e:
        logger.error("An error occurred while creating tables: %s", e)
        conn.rollback()


def main_int_db(database: str = "smart_elective_advisor.db") -> None:
    logger.info("Starting database setup...")

    db_directory = os.path.join(os.getcwd(), "db")

    if not os.path.exists(db_directory):
        os.makedirs(db_directory, exist_ok=True)
        logger.info("Created directory for database at %s", db_directory)

    db_path = os.path.join(db_directory, database)

    conn = create_connection(db_path)

    if conn is not None:
        try:
            create_tables(conn)
        except Exception as e:
            logger.error(
                "An error occurred during database setup at %s: %s", db_path, e
            )
            raise
        finally:
            conn.close()
            logger.info("Database setup completed. Database file: %s", db_path)
    else:
        logger.error("Error! Cannot create the database connection.")


def main_test_db(option: int) -> bool:
    """
    DB test dispatcher:
      option 1 -> call main_int_db(database="cli_test_db_option1.sqlite") (creates file under ./db)
      option 2 -> in-memory schema test (calls create_tables on ':memory:')
      option 3 -> tempfile smoke test (creates a temp sqlite file, runs simple insert/select)
    Returns True on success, False on failure.
    """
    logger.info("main_test_db: selected option %s", option)

    if option == 1:
        try:
            main_int_db(database="smart_elective_advisor.db")
            logger.info("main_test_db option 1: main_int_db completed successfully.")
            return True
        except Exception:
            logger.exception("main_test_db option 1 failed")
            return False

    elif option == 2:
        conn = None
        try:
            conn = create_connection(":memory:")
            if conn is None:
                logger.error(
                    "main_test_db option 2: failed to create in-memory connection"
                )
                return False
            create_tables(conn)
            logger.info("main_test_db option 2: in-memory create_tables OK")
            return True
        except Exception:
            logger.exception("main_test_db option 2 failed")
            return False
        finally:
            if conn:
                conn.close()

    elif option == 3:
        try:
            fd, tmp_path = tempfile.mkstemp(suffix=".sqlite")
            os.close(fd)
            logger.info("main_test_db option 3: temp DB at %s", tmp_path)
            conn = create_connection(tmp_path)
            if conn is None:
                logger.error(
                    "main_test_db option 3: failed to create temp DB connection"
                )
                try:
                    os.remove(tmp_path)
                except Exception:
                    pass
                return False
            create_tables(conn)
            cursor = conn.cursor()
            cursor.execute(
                "INSERT OR REPLACE INTO metadata (k, v) VALUES (?, ?)", ("t", "1")
            )
            conn.commit()
            cursor.execute("SELECT v FROM metadata WHERE k = ?", ("t",))
            r = cursor.fetchone()
            conn.close()
            os.remove(tmp_path)
            ok = r is not None and r[0] == "1"
            if ok:
                logger.info("main_test_db option 3: tempfile smoke test passed")
            else:
                logger.error(
                    "main_test_db option 3: tempfile smoke test failed (unexpected result)"
                )
            return ok
        except Exception:
            logger.exception("main_test_db option 3 failed")
            try:
                os.remove(tmp_path)
            except Exception:
                pass
            return False

    else:
        logger.error("main_test_db: unknown option %s", option)
        return False```

########################################
Here is my code for __init__.py BELOW:
########################################

```python
```

########################################
Here is my code for __init__.py BELOW:
########################################

```python
```

########################################
Here is my code for conftest.py BELOW:
########################################

```python
# tests/conftest.py
"""
tests/conftest.py
Project-wide pytest fixtures for the test suite.

This file is automatically discovered by pytest; fixtures defined here are available
to any test in the same directory tree without explicit imports. Use this file for
shared test setup/teardown utilities (env isolation, temporary paths, reusable
test data, etc.). See pytest docs for `conftest.py` and fixtures.
"""

import os
import tempfile

import pytest


@pytest.fixture(autouse=True)
def isolate_env(monkeypatch):
    """
    Automatically run for every test to provide environment isolation.

    Purpose:
      - Remove or normalize environment variables (for example OPENAI_API_KEY)
        so tests are deterministic and don't pick up values from the developer
        machine or CI runner.

    Behavior:
      - Runs before each test (function-scope by default).
      - Uses pytest's `monkeypatch` fixture to delete/set env vars; monkeypatch
        automatically restores changes after the test ends.
      - `raising=False` means deletion is silent if the var is already absent.
    """
    monkeypatch.delenv("OPENAI_API_KEY", raising=False)
    yield


@pytest.fixture
def valid_api_key(monkeypatch):
    """
    Provide a safe, valid-looking OPENAI_API_KEY for tests that require a key.

    Usage:
        def test_something(valid_api_key):
            assert os.getenv("OPENAI_API_KEY") == valid_api_key

    This uses monkeypatch.setenv so the environment is restored after the test.
    """
    key = "sk_test_" + "A" * 40
    monkeypatch.setenv("OPENAI_API_KEY", key)
    return key


```

########################################
Here is my code for test_ai_module.py BELOW:
########################################

```python
# tests/test_ai_module.py  # Added Code
"""Unit tests for ai_integration.ai_module."""

import inspect
import os
from importlib import util as importlib_util

import pytest

import ai_integration.ai_module as ai


def test_main_int_ai_returns_false_without_key():
    """isolate_env (autouse) removes OPENAI_API_KEY, so init should be False."""
    assert ai.main_int_ai() is False


def test_main_int_ai_returns_true_with_key(valid_api_key):
    """With a valid key set by the fixture, init should be True."""
    assert ai.main_int_ai() is True


def test_main_test_ai_option1_tracks_main_int_ai_without_key():
    """Option 1 proxies to main_int_ai; without key it should be False."""
    assert ai.main_test_ai(1) is False


def test_main_test_ai_option1_tracks_main_int_ai_with_key(valid_api_key):
    """Option 1 proxies to main_int_ai; with key it should be True."""
    assert ai.main_test_ai(1) is True


def test_main_test_ai_option2_returns_false_without_key():
    """Option 2: should warn/False when key is absent."""
    assert ai.main_test_ai(2) is False


def test_main_test_ai_option2_returns_true_with_key(valid_api_key):
    """Option 2: should True when key present (and log masked prefix)."""
    assert ai.main_test_ai(2) is True


def test_main_test_ai_option3_returns_false_when_openai_missing(
    monkeypatch,
):
    """Force find_spec('openai') -> None so option 3 returns False."""
    monkeypatch.setattr(
        ai.importlib.util, "find_spec", lambda name: None, raising=True
    )
    assert ai.main_test_ai(3) is False


def test_main_test_ai_option3_returns_true_when_openai_present(
    monkeypatch,
):
    """Force find_spec('openai') -> a dummy spec-like object so option 3 returns True."""
    monkeypatch.setattr(
        ai.importlib.util, "find_spec", lambda name: object(), raising=True
    )
    assert ai.main_test_ai(3) is True


def test_main_test_ai_unknown_option_returns_false():
    """Unknown option path should return False."""
    assert ai.main_test_ai(999) is False```

########################################
Here is my code for test_load_env.py BELOW:
########################################

```python
# tests/test_load_env.py
"""
Tests for utilities.load_env.load_environment().

Two behaviors are tested:
  1) When no API key is present (and no .env is found), load_environment() should raise ValueError.
  2) When a valid-looking API key is present, load_environment() should succeed (not raise).
"""

import pytest

from utilities import load_env


def test_load_environment_missing(monkeypatch):
    """
    Simulate "no .env file found" and "no OPENAI_API_KEY in environment".
    We patch load_env.find_dotenv to return an empty string so that the module's
    load_dotenv() call will not load any file, and delete OPENAI_API_KEY from env.
    """
    monkeypatch.setattr(load_env, "find_dotenv", lambda: "")

    monkeypatch.delenv("OPENAI_API_KEY", raising=False)

    with pytest.raises(ValueError):
        load_env.load_environment()


def test_load_environment_valid(tmp_path, monkeypatch):
    """
    Verify load_environment() succeeds when a valid-looking API key is available.
    Two options shown below — this test uses a direct environment set (fast).
    If you want to test file-based loading specifically, patch find_dotenv to return
    the path of the temp .env file instead of setting the env var directly.
    """

    monkeypatch.setenv("OPENAI_API_KEY", "sk_test_" + "A" * 40)

    load_env.load_environment()```

########################################
Here is my code for gui.py BELOW:
########################################

```python
import logging
import threading
import time
import tkinter as tk
from typing import Optional

logger = logging.getLogger(__name__)


def main_int_ui() -> None:
    """Initializes and runs the main interface of the Smart Elective Advisor."""

    logger.info("Initializing the Smart Elective Advisor GUI.")

    root = tk.Tk()
    root.title("Smart Elective Advisor")
    root.geometry("800x600")

    label = tk.Label(root, text="Welcome to Smart Elective Advisor")
    label.pack(padx=20, pady=20)

    def _on_close():
        logger.info("GUI received close request; shutting down.")
        root.destroy()

    root.protocol("WM_DELETE_WINDOW", _on_close)

    try:
        root.mainloop()
    except Exception:
        logger.exception("Error in GUI mainloop")
        raise


def main_test_ui(option: int) -> bool:
    """
    UI test dispatcher:
      option 1 -> launch the real GUI (blocking; user must close window)
      option 2 -> sanity create/destroy root without entering mainloop (fast)
      option 3 -> launch GUI and auto-close after 1 second (useful for CI)
    Returns True on success, False on failure.
    """
    logger.info("main_test_ui: selected option %s", option)

    if option == 1:
        try:
            main_int_ui()
            return True
        except Exception:
            logger.exception("main_test_ui option 1 failed")
            return False

    elif option == 2:
        try:
            root = tk.Tk()
            root.update_idletasks()
            root.destroy()
            logger.info("main_test_ui option 2: sanity create/destroy succeeded")
            return True
        except Exception:
            logger.exception("main_test_ui option 2 failed")
            return False

    elif option == 3:
        try:
            def _run_and_close():
                root = tk.Tk()
                root.title("Smart Elective Advisor (auto-close test)")
                label = tk.Label(root, text="Auto-close test (1s)")
                label.pack(padx=10, pady=10)
                root.after(1000, root.destroy)
                try:
                    root.mainloop()
                except Exception:
                    logger.exception("Exception in auto-close GUI thread")

            t = threading.Thread(target=_run_and_close, daemon=True)
            t.start()
            time.sleep(1.5)
            logger.info("main_test_ui option 3: auto-close GUI test completed")
            return True
        except Exception:
            logger.exception("main_test_ui option 3 failed")
            return False

    else:
        logger.error("main_test_ui: unknown option %s", option)
        return False```

########################################
Here is my code for __init__.py BELOW:
########################################

```python
```

########################################
Here is my code for load_env.py BELOW:
########################################

```python
# utilities/load_env.py

import logging
import os
import re
from pathlib import Path
from typing import Optional

from dotenv import find_dotenv, load_dotenv

logger = logging.getLogger(__name__)


def _validate_api_key(key: str) -> bool:
    """
    Conservative validation for the OpenAI API key:
    - must be at least 20 characters (adjust to your provider's expected length)
    - contains at least one alphanumeric character
    """
    if not key:
        return False
    if len(key) < 20:
        return False
    if not re.search(r"[A-Za-z0-9]", key):
        return False
    return True


def load_environment() -> None:
    """
    Load environment variables from .env (if present) and validate required vars.
    Raises ValueError on missing/invalid critical variables.
    """
    logger.info("Loading environment variables.")

    env_path = find_dotenv()
    if env_path:
        load_dotenv(env_path, override=False)
        logger.debug("Loaded .env from %s", env_path)
    else:
        logger.debug(
            ".env file not found; continuing with existing environment variables"
        )

    apikey = os.getenv("OPENAI_API_KEY")
    if not _validate_api_key(apikey or ""):
        logger.error("OPENAI_API_KEY is missing or invalid")
        raise ValueError("OPENAI_API_KEY environment variable missing or invalid")

    logger.info("API Key loaded successfully.")```

########################################
Here is my code for logger_setup.py BELOW:
########################################

```python
# utilities/logger_setup.py

import logging



def setup_logger():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s %(name)s:%(lineno)d %(message)s",
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler("app.log", mode="a"),
        ],
    )
    return logging.getLogger(__name__)```

########################################
Here is my pytest.ini BELOW:
########################################

```ini
#pytest.ini
[pytest]
# Minimum pytest version required for this repo — prevents running with older incompatible pytest.
# ensure pytest >= 7.0 is used (helps avoid subtle incompatibilities). 
minversion = 7.0  

# Default CLI options applied to every pytest invocation from this repo.
# - --strict-markers: fail on unknown/typoed @pytest.mark.X decorators (helps catch mis-typed markers).
#   If you enable strict markers, also declare your custom markers below via the `markers` option.
# - -q: quiet mode (limited console output); remove or use -v for verbose output in local debugging.
# - --cov=src: measure coverage for the `src` package (adjust path to your package directory if different).
# - --cov-report=term-missing: show coverage summary in terminal and list missing lines per file.
 # default flags for all runs. 
addopts = --strict-markers -q --cov=src --cov-report=term-missing 

# By default pytest will look here for tests when run from project root.
# keep tests in `tests/` directory to match this setting. 
testpaths = tests  

# Pattern used to detect test files. Ex: test_example.py, test_foo.py
# explicit discovery pattern; change if your test filenames differ.
python_files = test_*.py   



# Optional: explicitly declare any custom markers used in your suite to make marker usage discoverable
# (useful combined with --strict-markers so typos error out rather than silently being ignored).
# Example:
# markers =
#     slow: marks tests as slow (deselect with '-m "not slow"')
#     gui: marks tests that touch GUI code and may require headless setup
#
# If you use many custom markers, uncomment and list them here. 

```
